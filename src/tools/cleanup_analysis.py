#!/usr/bin/env python3
"""
Script de An√°lise de C√≥digo N√£o Utilizado
Robot-Crypt Cleanup Analysis

Este script analisa o projeto para identificar arquivos, depend√™ncias e c√≥digo n√£o utilizados.
"""

import os
import ast
import json
import glob
from pathlib import Path
from collections import defaultdict

class CleanupAnalyzer:
    def __init__(self, project_root="."):
        self.project_root = Path(project_root).resolve()
        self.unused_files = []
        self.unused_imports = []
        self.duplicate_code = []
        self.backend_references = []
        self.recommendations = []
        
    def analyze_python_files(self):
        """Analisa arquivos Python para imports e depend√™ncias"""
        python_files = list(self.project_root.glob("**/*.py"))
        # Exclui arquivos em .venv, backend/, e backend_new/
        python_files = [f for f in python_files if not any(
            part.startswith('.') or part in ['backend', 'backend_new', '__pycache__']
            for part in f.parts
        )]
        
        imports_by_file = {}
        all_imports = set()
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Parse AST para encontrar imports
                tree = ast.parse(content)
                file_imports = []
                
                for node in ast.walk(tree):
                    if isinstance(node, ast.Import):
                        for alias in node.names:
                            file_imports.append(alias.name)
                            all_imports.add(alias.name)
                    elif isinstance(node, ast.ImportFrom):
                        if node.module:
                            file_imports.append(node.module)
                            all_imports.add(node.module)
                
                imports_by_file[file_path] = file_imports
                
            except Exception as e:
                print(f"Erro ao analisar {file_path}: {e}")
        
        return imports_by_file, all_imports
    
    def find_unused_files(self):
        """Identifica arquivos potencialmente n√£o utilizados"""
        # Arquivos que parecem n√£o ser usados pelo projeto principal
        potential_unused = []
        
        # Scripts de setup e teste que podem ser consolidados
        setup_scripts = list(self.project_root.glob("setup*.sh")) + list(self.project_root.glob("setup*.py"))
        test_scripts = list(self.project_root.glob("test_*.py"))
        
        # Arquivos de migra√ß√£o e manuten√ß√£o antigos
        migration_files = [
            "migrate_stats.py",
            "update_simulation_field.py",
            "populate_database.py",
            "maintenance_tool.py",
            "binance_data_sync.py"
        ]
        
        # Scripts duplicados ou obsoletos
        duplicate_scripts = [
            "dashboard.py",  # parece n√£o existir mais
            "run_dashboard.py",
            "start_dashboard.sh",
            "simple_test.py",
            "test_execution.py",
            "test_imports.py",
            "test_postgres.py",
            "test_startup.py"
        ]
        
        for file_pattern in migration_files + duplicate_scripts:
            file_path = self.project_root / file_pattern
            if file_path.exists():
                potential_unused.append(file_path)
        
        # Analisa scripts de setup
        for script in setup_scripts:
            if "real" in script.name or "testnet" in script.name:
                potential_unused.append(script)
        
        # Analisa scripts de teste isolados
        for script in test_scripts:
            if script.name not in ["test_strategy.py", "test_simulator.py"]:
                potential_unused.append(script)
        
        return potential_unused
    
    def analyze_backend_references(self):
        """Verifica se h√° refer√™ncias ao diret√≥rio backend/"""
        backend_refs = []
        
        # Busca por imports ou refer√™ncias ao backend antigo
        for py_file in self.project_root.glob("**/*.py"):
            if any(part in ['backend', 'backend_new', '.venv', '__pycache__'] for part in py_file.parts):
                continue
                
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Procura por refer√™ncias ao backend
                if 'backend/' in content or 'from backend' in content or 'import backend' in content:
                    lines = content.split('\n')
                    for i, line in enumerate(lines):
                        if 'backend' in line and ('import' in line or 'from' in line):
                            backend_refs.append({
                                'file': py_file,
                                'line': i + 1,
                                'content': line.strip()
                            })
            except Exception as e:
                print(f"Erro ao analisar {py_file}: {e}")
        
        return backend_refs
    
    def analyze_notifications_spam(self):
        """Analisa arquivos de notifica√ß√£o duplicados"""
        notifications_dir = self.project_root / "notifications"
        if notifications_dir.exists():
            notification_files = list(notifications_dir.glob("notification_*.txt"))
            return len(notification_files), notification_files
        return 0, []
    
    def check_duplicate_functionality(self):
        """Verifica funcionalidades duplicadas"""
        duplicates = []
        
        # Dashboard duplicado
        dashboard_files = []
        for pattern in ["dashboard*.py", "dashboard/*", "robot_crypt_dashboard.py"]:
            dashboard_files.extend(list(self.project_root.glob(pattern)))
        
        if len(dashboard_files) > 1:
            duplicates.append({
                'type': 'dashboard',
                'files': dashboard_files,
                'description': 'M√∫ltiplas implementa√ß√µes de dashboard encontradas'
            })
        
        # Simuladores duplicados
        simulator_files = list(self.project_root.glob("*simulator*.py"))
        if len(simulator_files) > 1:
            duplicates.append({
                'type': 'simulator',
                'files': simulator_files,
                'description': 'M√∫ltiplos simuladores encontrados'
            })
        
        # APIs Binance duplicadas
        binance_files = list(self.project_root.glob("binance*.py"))
        if len(binance_files) > 2:  # main + simulator √© ok
            duplicates.append({
                'type': 'binance_api',
                'files': binance_files,
                'description': 'M√∫ltiplas implementa√ß√µes da API Binance'
            })
        
        return duplicates
    
    def generate_cleanup_plan(self):
        """Gera plano detalhado de limpeza"""
        plan = {
            'files_to_remove': [],
            'files_to_consolidate': [],
            'directories_to_clean': [],
            'code_to_refactor': [],
            'estimated_space_savings': 0
        }
        
        # Analisa arquivos n√£o utilizados
        unused_files = self.find_unused_files()
        for file_path in unused_files:
            try:
                size = file_path.stat().st_size
                plan['files_to_remove'].append({
                    'path': str(file_path.relative_to(self.project_root)),
                    'size_bytes': size,
                    'reason': 'Aparenta n√£o ser usado pelo projeto principal'
                })
                plan['estimated_space_savings'] += size
            except:
                pass
        
        # Analisa notifica√ß√µes em massa
        notif_count, notif_files = self.analyze_notifications_spam()
        if notif_count > 10:
            # Remove arquivos antigos, mant√©m apenas os √∫ltimos 5
            files_to_keep = sorted(notif_files, key=lambda x: x.stat().st_mtime)[-5:]
            files_to_remove = [f for f in notif_files if f not in files_to_keep]
            
            total_size = sum(f.stat().st_size for f in files_to_remove)
            plan['files_to_remove'].append({
                'path': 'notifications/',
                'count': len(files_to_remove),
                'size_bytes': total_size,
                'reason': f'Limpeza de {len(files_to_remove)} arquivos de notifica√ß√£o antigos'
            })
            plan['estimated_space_savings'] += total_size
        
        # Analisa duplicatas
        duplicates = self.check_duplicate_functionality()
        for duplicate in duplicates:
            plan['files_to_consolidate'].append({
                'type': duplicate['type'],
                'files': [str(f) for f in duplicate['files']],
                'description': duplicate['description']
            })
        
        # Diret√≥rio backend/ completo
        backend_dir = self.project_root / "backend"
        if backend_dir.exists():
            try:
                # Calcula tamanho do diret√≥rio backend
                total_size = sum(f.stat().st_size for f in backend_dir.rglob("*") if f.is_file())
                plan['directories_to_clean'].append({
                    'path': 'backend/',
                    'size_bytes': total_size,
                    'reason': 'Migra√ß√£o para backend_new/ conclu√≠da'
                })
                plan['estimated_space_savings'] += total_size
            except:
                pass
        
        return plan
    
    def run_analysis(self):
        """Executa an√°lise completa"""
        print("üîç Iniciando an√°lise de limpeza do Robot-Crypt...")
        
        # 1. Analisa imports e depend√™ncias
        print("üì¶ Analisando imports e depend√™ncias...")
        imports_by_file, all_imports = self.analyze_python_files()
        
        # 2. Encontra arquivos n√£o utilizados
        print("üóëÔ∏è Identificando arquivos n√£o utilizados...")
        unused_files = self.find_unused_files()
        
        # 3. Verifica refer√™ncias ao backend antigo
        print("üîó Verificando refer√™ncias ao backend antigo...")
        backend_refs = self.analyze_backend_references()
        
        # 4. Analisa notifica√ß√µes em massa
        print("üì¢ Analisando arquivos de notifica√ß√£o...")
        notif_count, notif_files = self.analyze_notifications_spam()
        
        # 5. Verifica duplicatas
        print("üë• Verificando funcionalidades duplicadas...")
        duplicates = self.check_duplicate_functionality()
        
        # 6. Gera plano de limpeza
        print("üìã Gerando plano de limpeza...")
        cleanup_plan = self.generate_cleanup_plan()
        
        return {
            'summary': {
                'total_python_files': len(imports_by_file),
                'unused_files_count': len(unused_files),
                'backend_references': len(backend_refs),
                'notification_files': notif_count,
                'duplicate_groups': len(duplicates),
                'estimated_space_savings_mb': cleanup_plan['estimated_space_savings'] / (1024 * 1024)
            },
            'unused_files': [str(f.relative_to(self.project_root)) for f in unused_files],
            'backend_references': backend_refs,
            'notification_analysis': {
                'count': notif_count,
                'recommendation': 'Manter apenas os 5 mais recentes' if notif_count > 10 else 'OK'
            },
            'duplicates': duplicates,
            'cleanup_plan': cleanup_plan
        }

def main():
    analyzer = CleanupAnalyzer()
    results = analyzer.run_analysis()
    
    print("\n" + "="*80)
    print("üìä RELAT√ìRIO DE AN√ÅLISE DE LIMPEZA - ROBOT-CRYPT")
    print("="*80)
    
    summary = results['summary']
    print(f"""
üìà RESUMO:
  ‚Ä¢ Arquivos Python analisados: {summary['total_python_files']}
  ‚Ä¢ Arquivos n√£o utilizados: {summary['unused_files_count']}
  ‚Ä¢ Refer√™ncias ao backend antigo: {summary['backend_references']}
  ‚Ä¢ Arquivos de notifica√ß√£o: {summary['notification_files']}
  ‚Ä¢ Grupos de duplicatas: {summary['duplicate_groups']}
  ‚Ä¢ Economia estimada: {summary['estimated_space_savings_mb']:.2f} MB
""")
    
    if results['unused_files']:
        print("\nüóëÔ∏è ARQUIVOS POTENCIALMENTE N√ÉO UTILIZADOS:")
        for file_path in results['unused_files']:
            print(f"  ‚Ä¢ {file_path}")
    
    if results['backend_references']:
        print("\n‚ö†Ô∏è REFER√äNCIAS AO BACKEND ANTIGO ENCONTRADAS:")
        for ref in results['backend_references']:
            print(f"  ‚Ä¢ {ref['file']}:{ref['line']} - {ref['content']}")
    
    if results['notification_analysis']['count'] > 10:
        print(f"\nüì¢ LIMPEZA DE NOTIFICA√á√ïES RECOMENDADA:")
        print(f"  ‚Ä¢ Encontrados {results['notification_analysis']['count']} arquivos de notifica√ß√£o")
        print(f"  ‚Ä¢ Recomenda√ß√£o: {results['notification_analysis']['recommendation']}")
    
    if results['duplicates']:
        print("\nüë• FUNCIONALIDADES DUPLICADAS:")
        for dup in results['duplicates']:
            print(f"  ‚Ä¢ Tipo: {dup['type']}")
            print(f"    Descri√ß√£o: {dup['description']}")
            print(f"    Arquivos: {', '.join([str(f) for f in dup['files']])}")
    
    print("\n" + "="*80)
    print("üéØ RECOMENDA√á√ïES DE LIMPEZA:")
    print("="*80)
    
    recommendations = [
        "1. REMOVER diret√≥rio backend/ completo (migra√ß√£o para backend_new/ conclu√≠da)",
        "2. CONSOLIDAR scripts de setup em um √∫nico script",
        "3. LIMPAR arquivos de notifica√ß√£o antigos (manter apenas os 5 mais recentes)",
        "4. REMOVER scripts de teste isolados que n√£o s√£o mais utilizados",
        "5. VERIFICAR se os m√≥dulos de dashboard duplicados podem ser unificados",
        "6. ATUALIZAR imports que ainda referenciam o backend antigo",
        "7. CONSIDERAR mover scripts de manuten√ß√£o para um diret√≥rio separado 'tools/'",
        "8. VERIFICAR se requirements.txt cont√©m depend√™ncias n√£o utilizadas"
    ]
    
    for rec in recommendations:
        print(f"  {rec}")
    
    print(f"\nüíæ Economia estimada total: {summary['estimated_space_savings_mb']:.2f} MB")
    print("\n‚úÖ An√°lise conclu√≠da! Execute as a√ß√µes recomendadas conforme necess√°rio.")
    
    # Salva relat√≥rio em arquivo
    report_path = Path("cleanup_report.json")
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\nüìÑ Relat√≥rio detalhado salvo em: {report_path}")

if __name__ == "__main__":
    main()
