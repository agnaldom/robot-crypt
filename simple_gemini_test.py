#!/usr/bin/env python3
"""
Teste simples do Gemini
"""

import asyncio
import sys
import os

# Add the src directory to the path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from ai.llm_client import get_llm_client

async def main():
    print("ğŸ§ª Teste Simples do Gemini")
    
    try:
        client = get_llm_client()
        print(f"Provider: {client.provider}")
        print(f"Model: {client.model}")
        
        # Teste bÃ¡sico
        print("\n1. Teste bÃ¡sico...")
        response = await client.chat("OlÃ¡! Como vocÃª estÃ¡?")
        print(f"âœ… Response: {response.content}")
        print(f"ğŸ“Š Tokens: {response.tokens_used}")
        print(f"ğŸ’° Cost: ${response.cost_estimate:.6f}")
        
        # Teste anÃ¡lise crypto
        print("\n2. Teste anÃ¡lise crypto...")
        crypto_prompt = "Analise brevemente o Bitcoin como investimento."
        response = await client.chat(crypto_prompt)
        print(f"âœ… Response: {response.content[:200]}...")
        print(f"ğŸ“Š Tokens: {response.tokens_used}")
        
        # Teste JSON
        print("\n3. Teste JSON...")
        json_prompt = "ForneÃ§a uma anÃ¡lise JSON do mercado de Bitcoin com campos: sentiment, confidence, trend."
        response = await client.analyze_json(json_prompt)
        print(f"âœ… JSON Response: {response}")
        
        print("\nğŸ‰ Todos os testes concluÃ­dos!")
        
    except Exception as e:
        print(f"âŒ Erro: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
